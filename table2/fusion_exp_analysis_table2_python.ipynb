{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a4dc33-5506-4848-90f9-a289dd113f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/ssd/kangdang/mmc_project_2023_submission/main_exp_code/step4_exp_analysis')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as pathlib\n",
    "from stats_fun import cal_ci95\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "output_dir = '/ssd/kangdang/mmc_project_2023_submission/main_exp_code/step4_exp_analysis/table2/fusion_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77cdae96-5324-4f9a-a42a-52a9d7a05daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_and_gt_helper(input_dir, method_id, feature_id, fusion_type='metric_only', imputation_type='mi'):\n",
    "    if imputation_type == 'mi':\n",
    "        input_dir = pathlib.join(input_dir, method_id)\n",
    "        val_pred_list = list()\n",
    "        val_gt_list = list()\n",
    "        test_pred_list = list()\n",
    "        test_gt_list = list()\n",
    "        for mice_id in range(20):\n",
    "            curr_folder = pathlib.join(input_dir, 'mice_imputation_' + str(mice_id+ 1), fusion_type)\n",
    "            val_score = pd.read_csv(pathlib.join(curr_folder, \"feat_[\" + str(feature_id) + \"]_val_pred_result.csv\"))\n",
    "            test_score = pd.read_csv(pathlib.join(curr_folder, \"feat_[\" + str(feature_id) + \"]_test_pred_result.csv\"))\n",
    "            val_pred_list.append(np.array(val_score['pred']))\n",
    "            val_gt_list.append(np.array(val_score['gt']))\n",
    "            test_pred_list.append(np.array(test_score['pred']))\n",
    "            test_gt_list.append(np.array(test_score['gt']))   \n",
    "        val_gt_list = val_gt_list[0]\n",
    "        test_gt_list = test_gt_list[0]\n",
    "        val_pred_list = np.mean(np.array(val_pred_list), axis = 0)\n",
    "        test_pred_list = np.mean(np.array(test_pred_list), axis = 0)\n",
    "    else:\n",
    "        curr_folder = pathlib.join(input_dir, method_id, fusion_type)\n",
    "        val_score = pd.read_csv(pathlib.join(curr_folder, \"feat_[\" + str(feature_id) + \"]_val_pred_result.csv\"))\n",
    "        test_score = pd.read_csv(pathlib.join(curr_folder, \"feat_[\" + str(feature_id) + \"]_test_pred_result.csv\"))\n",
    "        val_pred_list = np.array(val_score['pred'])\n",
    "        val_gt_list = np.array(val_score['gt'])\n",
    "        test_pred_list = np.array(test_score['pred'])\n",
    "        test_gt_list = np.array(test_score['gt'])\n",
    "    return  val_gt_list, test_gt_list, val_pred_list, test_pred_list\n",
    "\n",
    "\n",
    "def get_score_and_gt(input_dir, feature_id, fusion_type='metric_only', imputation_type='mi', method_id_list = ['method_lr_basic', 'method_lda_basic',  'method_gbc_basic', 'method_rf_basic',  'method_lsvm_basic',  'method_rbfsvm_basic'] ):\n",
    "    val_auc_list = []\n",
    "    for method_id in method_id_list:\n",
    "        val_gt_list, test_gt_list, val_pred_list, test_pred_list  = get_score_and_gt_helper(input_dir, method_id, feature_id, fusion_type, imputation_type)\n",
    "        fpr, tpr, threshold = metrics.roc_curve(val_gt_list, val_pred_list)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        fpr_test, tpr_test, _ = metrics.roc_curve(test_gt_list, test_pred_list)\n",
    "        auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "        print(method_id + ':' + str(round(auc, 3)) + ', ' + str(round(auc_test, 3)))\n",
    "        val_auc_list.append(auc)\n",
    "    \n",
    "    best_val_idx = np.argmax(val_auc_list)\n",
    "    best_method_id = np.array(method_id_list)[best_val_idx]\n",
    "    val_gt_list, test_gt_list, val_pred_list, test_pred_list = get_score_and_gt_helper(input_dir, best_method_id, feature_id, fusion_type, imputation_type)\n",
    "    return best_method_id, val_gt_list, test_gt_list, val_pred_list, test_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd4a070-48ff-4f14-ade2-e377695e8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_merged_dataframe(input_dir, metric_string, save_name, imputation_type='mi', method_id_list = ['method_lr_basic']):\n",
    "    model_type_metric_only, _, test_gt_list0, _, test_pred_list0 = get_score_and_gt(input_dir, metric_string, \"metric_only\", imputation_type, method_id_list = method_id_list)\n",
    "    model_type_fusion, _, test_gt_list1, _, test_pred_list1 = get_score_and_gt(input_dir, metric_string, \"fusion\", imputation_type, method_id_list = method_id_list)\n",
    "    \n",
    "    print('metric_only')\n",
    "    auc95, rec, sep, sep_90, global_auc, global_rec, global_sep, global_sep_90, global_largest_youden_th_metric, global_given_recall_th_metric = cal_ci95(test_gt_list0, test_pred_list0, 0.8)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(test_gt_list0, test_pred_list0)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print('auc')\n",
    "    print(\"[\" + \"{:.1f}\".format(auc95[0] * 100) + \",\" + \"{:.1f}\".format(auc95[1] * 100) + \"]\")\n",
    "    print(\"{:.1f}\".format(auc * 100))\n",
    "    print('recall')\n",
    "    print(\"[\" + \"{:.1f}\".format(rec[0] * 100) + \",\" + \"{:.1f}\".format(rec[1] * 100) + \"]\")\n",
    "    print(\"{:.1f}\".format(global_rec * 100))\n",
    "    print('sep')\n",
    "    print(\"[\" + \"{:.1f}\".format(sep[0] * 100) + \",\" + \"{:.1f}\".format(sep[1] * 100) + \"]\")\n",
    "    print(\"{:.1f}\".format(global_sep * 100))\n",
    "    \n",
    "\n",
    "    print('fusion')\n",
    "    auc95, rec, sep, sep_90, global_auc, global_rec, global_sep, global_sep_90, global_largest_youden_th_fusion, global_given_recall_th_fusion = cal_ci95(test_gt_list1, test_pred_list1, 0.8)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(test_gt_list1, test_pred_list1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print('auc')\n",
    "    print(\"[\" + \"{:.1f}\".format(auc95[0] * 100) + \",\" + \"{:.1f}\".format(auc95[1] * 100) + \"]\")\n",
    "    print(\"{:.1f}\".format(auc * 100))\n",
    "    print('recall')\n",
    "    print(\"[\" + \"{:.1f}\".format(rec[0] * 100) + \",\" + \"{:.1f}\".format(rec[1] * 100) + \"]\")\n",
    "    print(\"{:.1f}\".format(global_rec * 100))\n",
    "    print('sep')\n",
    "    print(\"[\" + \"{:.1f}\".format(sep[0] * 100) + \",\" + \"{:.1f}\".format(sep[1] * 100) + \"]\")\n",
    "    print(\"{:.1f}\".format(global_sep * 100))\n",
    "    \n",
    "    \n",
    "    assert((test_gt_list0 == test_gt_list1).all())\n",
    "    merge_data_list = list()\n",
    "    merge_data_list.append(test_gt_list0)\n",
    "    merge_data_list.append(test_pred_list0)\n",
    "    merge_data_list.append(test_pred_list1)\n",
    "    merge_data_list.append(np.array(test_pred_list0) >= global_largest_youden_th_metric)\n",
    "    merge_data_list.append(np.array(test_pred_list1) >= global_largest_youden_th_fusion) \n",
    "    \n",
    "    merge_data_list = np.array(merge_data_list)\n",
    "    merged_data_list = merge_data_list.transpose()\n",
    "\n",
    "    merged_data_frame = pd.DataFrame(merged_data_list, columns=['target', 'metric', 'fusion', 'metric_th', 'fusion_th'])\n",
    "    merged_data_frame.to_csv(pathlib.join(output_dir, save_name), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e64e8d-88b6-4bb4-9f8e-266f62d472df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_lr_basic:0.855, 0.847\n",
      "method_lr_basic:0.864, 0.853\n",
      "metric_only\n",
      "auc\n",
      "[84.0,85.5]\n",
      "84.7\n",
      "recall\n",
      "[77.0,78.9]\n",
      "77.9\n",
      "sep\n",
      "[74.4,77.3]\n",
      "75.8\n",
      "fusion\n",
      "auc\n",
      "[84.6,86.1]\n",
      "85.3\n",
      "recall\n",
      "[77.3,79.2]\n",
      "78.2\n",
      "sep\n",
      "[75.4,78.4]\n",
      "76.9\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_mi'\n",
    "metric_string = \"'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'\"\n",
    "save_name = 'scenario_random_metric_and_fusion_score.csv'\n",
    "save_merged_dataframe(input_dir, metric_string, save_name, method_id_list = ['method_lr_basic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69e305f-1cc9-4ceb-be60-674969c178f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_lr_basic:0.853, 0.844\n",
      "method_lr_basic:0.862, 0.849\n",
      "metric_only\n",
      "auc\n",
      "[83.6,85.3]\n",
      "84.4\n",
      "recall\n",
      "[75.1,77.2]\n",
      "76.2\n",
      "sep\n",
      "[75.5,78.6]\n",
      "77.1\n",
      "fusion\n",
      "auc\n",
      "[84.1,85.7]\n",
      "84.9\n",
      "recall\n",
      "[76.4,78.4]\n",
      "77.3\n",
      "sep\n",
      "[74.9,78.1]\n",
      "76.6\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_remove_any_nan_sample'\n",
    "metric_string = \"'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'\"\n",
    "save_name = 'scenario_random_metric_and_fusion_score_no_imputation.csv'\n",
    "save_merged_dataframe(input_dir, metric_string, save_name, imputation_type='random_remove_any_nan_sample', method_id_list = ['method_lr_basic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3325d869-77da-44e6-b1e7-11773949d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_lr_basic:0.855, 0.847\n",
      "method_lr_basic:0.864, 0.853\n",
      "metric_only\n",
      "auc\n",
      "[84.0,85.5]\n",
      "84.7\n",
      "recall\n",
      "[77.3,79.2]\n",
      "78.2\n",
      "sep\n",
      "[74.1,77.0]\n",
      "75.5\n",
      "fusion\n",
      "auc\n",
      "[84.6,86.1]\n",
      "85.3\n",
      "recall\n",
      "[78.5,80.2]\n",
      "79.3\n",
      "sep\n",
      "[73.7,76.9]\n",
      "75.3\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_simple_imputation'\n",
    "metric_string = \"'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'\"\n",
    "save_name = 'scenario_random_metric_and_fusion_score_simple_imputation.csv'\n",
    "save_merged_dataframe(input_dir, metric_string, save_name, imputation_type='simple', method_id_list = ['method_lr_basic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36c13bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_lda_basic:0.853, 0.846\n",
      "method_lda_basic:0.861, 0.851\n",
      "metric_only\n",
      "auc\n",
      "[83.8,85.4]\n",
      "84.6\n",
      "recall\n",
      "[78.7,80.5]\n",
      "79.6\n",
      "sep\n",
      "[71.7,74.7]\n",
      "73.2\n",
      "fusion\n",
      "auc\n",
      "[84.3,85.9]\n",
      "85.1\n",
      "recall\n",
      "[74.7,76.6]\n",
      "75.6\n",
      "sep\n",
      "[77.1,79.9]\n",
      "78.5\n"
     ]
    }
   ],
   "source": [
    "# method_id_list = ['method_lr_basic', 'method_lda_basic',  'method_gbc_basic', 'method_rf_basic',  'method_lsvm_basic',  'method_rbfsvm_basic']\n",
    "input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_mi'\n",
    "metric_string = \"'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'\"\n",
    "save_name = 'scenario_random_metric_and_fusion_score_lda.csv'\n",
    "save_merged_dataframe(input_dir, metric_string, save_name, method_id_list = ['method_lda_basic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d657710a-d081-4f42-bc68-0daf6c835d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_gbc_basic:0.854, 0.847\n",
      "method_gbc_basic:0.855, 0.841\n",
      "metric_only\n",
      "auc\n",
      "[83.9,85.5]\n",
      "84.7\n",
      "recall\n",
      "[75.8,77.7]\n",
      "76.7\n",
      "sep\n",
      "[75.9,78.8]\n",
      "77.4\n",
      "fusion\n",
      "auc\n",
      "[83.3,84.9]\n",
      "84.1\n",
      "recall\n",
      "[74.0,76.0]\n",
      "75.0\n",
      "sep\n",
      "[76.3,79.0]\n",
      "77.6\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_mi'\n",
    "metric_string = \"'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'\"\n",
    "save_name = 'scenario_random_metric_and_fusion_score_gbc.csv'\n",
    "save_merged_dataframe(input_dir, metric_string, save_name, method_id_list = ['method_gbc_basic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deb71cb1-fca8-441a-b81b-9a42466d6c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_rf_basic:0.849, 0.84\n",
      "method_rf_basic:0.853, 0.842\n",
      "metric_only\n",
      "auc\n",
      "[83.2,84.8]\n",
      "84.0\n",
      "recall\n",
      "[74.0,76.0]\n",
      "75.0\n",
      "sep\n",
      "[76.2,79.0]\n",
      "77.6\n",
      "fusion\n",
      "auc\n",
      "[83.3,84.9]\n",
      "84.2\n",
      "recall\n",
      "[71.7,73.7]\n",
      "72.7\n",
      "sep\n",
      "[78.1,80.9]\n",
      "79.5\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_mi'\n",
    "metric_string = \"'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'\"\n",
    "save_name = 'scenario_random_metric_and_fusion_score_rf.csv'\n",
    "save_merged_dataframe(input_dir, metric_string, save_name, method_id_list = ['method_rf_basic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa99bda6-0fae-4c6b-994d-c51816cc6f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_lsvm_basic:0.854, 0.846\n",
      "method_lsvm_basic:0.861, 0.852\n",
      "metric_only\n",
      "auc\n",
      "[83.9,85.4]\n",
      "84.6\n",
      "recall\n",
      "[75.5,77.5]\n",
      "76.5\n",
      "sep\n",
      "[75.3,78.1]\n",
      "76.7\n",
      "fusion\n",
      "auc\n",
      "[84.4,86.0]\n",
      "85.2\n",
      "recall\n",
      "[74.7,76.6]\n",
      "75.6\n",
      "sep\n",
      "[77.4,80.2]\n",
      "78.8\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_mi'\n",
    "metric_string = \"'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'\"\n",
    "save_name = 'scenario_random_metric_and_fusion_score_lsvm.csv'\n",
    "save_merged_dataframe(input_dir, metric_string, save_name, method_id_list = ['method_lsvm_basic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f313bf86-f5f2-4dc3-86ef-d7baeef39e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_rbfsvm_basic:0.847, 0.836\n",
      "method_rbfsvm_basic:0.855, 0.842\n",
      "metric_only\n",
      "auc\n",
      "[82.7,84.4]\n",
      "83.6\n",
      "recall\n",
      "[74.1,76.1]\n",
      "75.0\n",
      "sep\n",
      "[76.3,79.1]\n",
      "77.7\n",
      "fusion\n",
      "auc\n",
      "[83.4,85.1]\n",
      "84.2\n",
      "recall\n",
      "[77.9,79.8]\n",
      "78.8\n",
      "sep\n",
      "[74.3,77.3]\n",
      "75.7\n"
     ]
    }
   ],
   "source": [
    "input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_mi'\n",
    "metric_string = \"'1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'\"\n",
    "save_name = 'scenario_random_metric_and_fusion_score_rbf_svm.csv'\n",
    "save_merged_dataframe(input_dir, metric_string, save_name, method_id_list = ['method_rbfsvm_basic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed32d61a-24f0-40ad-88d6-6cf33b654dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "method_lr_basic:0.534, 0.536\n",
      "method_lr_basic:0.795, 0.78\n",
      "metric_only\n",
      "auc\n",
      "[52.5,54.6]\n",
      "53.6\n",
      "recall\n",
      "[42.5,44.8]\n",
      "43.7\n",
      "sep\n",
      "[61.8,65.2]\n",
      "63.6\n",
      "fusion\n",
      "auc\n",
      "[77.1,79.0]\n",
      "78.0\n",
      "recall\n",
      "[67.4,69.4]\n",
      "68.4\n",
      "sep\n",
      "[72.3,75.5]\n",
      "73.9\n",
      "\n",
      "\n",
      "Age\n",
      "method_lr_basic:0.764, 0.766\n",
      "method_lr_basic:0.804, 0.794\n",
      "metric_only\n",
      "auc\n",
      "[75.6,77.6]\n",
      "76.6\n",
      "recall\n",
      "[70.0,72.1]\n",
      "71.1\n",
      "sep\n",
      "[65.9,69.2]\n",
      "67.5\n",
      "fusion\n",
      "auc\n",
      "[78.5,80.3]\n",
      "79.4\n",
      "recall\n",
      "[72.8,74.7]\n",
      "73.7\n",
      "sep\n",
      "[68.7,71.9]\n",
      "70.2\n",
      "\n",
      "\n",
      "Diastolic Bp\n",
      "method_lr_basic:0.649, 0.631\n",
      "method_lr_basic:0.816, 0.801\n",
      "metric_only\n",
      "auc\n",
      "[62.0,64.2]\n",
      "63.1\n",
      "recall\n",
      "[49.3,51.6]\n",
      "50.5\n",
      "sep\n",
      "[67.2,70.3]\n",
      "68.7\n",
      "fusion\n",
      "auc\n",
      "[79.1,81.0]\n",
      "80.1\n",
      "recall\n",
      "[71.4,73.4]\n",
      "72.5\n",
      "sep\n",
      "[72.2,75.3]\n",
      "73.7\n",
      "\n",
      "\n",
      "Systolic Bp\n",
      "method_lr_basic:0.758, 0.749\n",
      "method_lr_basic:0.841, 0.83\n",
      "metric_only\n",
      "auc\n",
      "[73.9,75.9]\n",
      "74.9\n",
      "recall\n",
      "[59.5,61.9]\n",
      "60.7\n",
      "sep\n",
      "[75.3,78.3]\n",
      "76.8\n",
      "fusion\n",
      "auc\n",
      "[82.1,83.8]\n",
      "83.0\n",
      "recall\n",
      "[76.3,78.3]\n",
      "77.3\n",
      "sep\n",
      "[71.5,74.7]\n",
      "73.1\n",
      "\n",
      "\n",
      "Heart Rate\n",
      "method_lr_basic:0.537, 0.535\n",
      "method_lr_basic:0.801, 0.786\n",
      "metric_only\n",
      "auc\n",
      "[52.2,54.7]\n",
      "53.5\n",
      "recall\n",
      "[68.0,70.1]\n",
      "69.0\n",
      "sep\n",
      "[35.0,38.3]\n",
      "36.6\n",
      "fusion\n",
      "auc\n",
      "[77.7,79.5]\n",
      "78.6\n",
      "recall\n",
      "[68.0,70.1]\n",
      "69.0\n",
      "sep\n",
      "[72.4,75.4]\n",
      "73.9\n",
      "\n",
      "\n",
      "BMI\n",
      "method_lr_basic:0.511, 0.526\n",
      "method_lr_basic:0.794, 0.78\n",
      "metric_only\n",
      "auc\n",
      "[51.4,53.8]\n",
      "52.6\n",
      "recall\n",
      "[72.5,74.5]\n",
      "73.5\n",
      "sep\n",
      "[30.9,34.3]\n",
      "32.7\n",
      "fusion\n",
      "auc\n",
      "[77.1,79.0]\n",
      "78.0\n",
      "recall\n",
      "[68.1,70.1]\n",
      "69.1\n",
      "sep\n",
      "[71.6,74.8]\n",
      "73.1\n",
      "\n",
      "\n",
      "Course of Diabetes\n",
      "method_lr_basic:0.657, 0.657\n",
      "method_lr_basic:0.798, 0.785\n",
      "metric_only\n",
      "auc\n",
      "[64.6,66.8]\n",
      "65.7\n",
      "recall\n",
      "[56.4,58.6]\n",
      "57.4\n",
      "sep\n",
      "[66.6,69.8]\n",
      "68.2\n",
      "fusion\n",
      "auc\n",
      "[77.6,79.5]\n",
      "78.5\n",
      "recall\n",
      "[67.6,69.6]\n",
      "68.6\n",
      "sep\n",
      "[72.8,75.9]\n",
      "74.3\n",
      "\n",
      "\n",
      "Hypertension\n",
      "method_lr_basic:0.646, 0.649\n",
      "method_lr_basic:0.804, 0.791\n",
      "metric_only\n",
      "auc\n",
      "[64.0,65.9]\n",
      "64.9\n",
      "recall\n",
      "[49.7,52.0]\n",
      "50.8\n",
      "sep\n",
      "[78.7,81.6]\n",
      "80.2\n",
      "fusion\n",
      "auc\n",
      "[78.2,80.0]\n",
      "79.1\n",
      "recall\n",
      "[72.6,74.6]\n",
      "73.6\n",
      "sep\n",
      "[69.5,72.7]\n",
      "71.0\n",
      "\n",
      "\n",
      "Hyperlipidemia\n",
      "method_lr_basic:0.536, 0.534\n",
      "method_lr_basic:0.796, 0.781\n",
      "metric_only\n",
      "auc\n",
      "[52.4,54.4]\n",
      "53.4\n",
      "recall\n",
      "[34.1,36.2]\n",
      "35.1\n",
      "sep\n",
      "[71.3,74.4]\n",
      "72.9\n",
      "fusion\n",
      "auc\n",
      "[77.1,79.1]\n",
      "78.1\n",
      "recall\n",
      "[71.4,73.3]\n",
      "72.4\n",
      "sep\n",
      "[68.3,71.5]\n",
      "69.8\n",
      "\n",
      "\n",
      "Cardiovascular Disease\n",
      "method_lr_basic:0.547, 0.551\n",
      "method_lr_basic:0.794, 0.78\n",
      "metric_only\n",
      "auc\n",
      "[54.3,55.8]\n",
      "55.1\n",
      "recall\n",
      "[18.3,20.1]\n",
      "19.2\n",
      "sep\n",
      "[91.3,93.1]\n",
      "92.3\n",
      "fusion\n",
      "auc\n",
      "[77.1,79.0]\n",
      "78.0\n",
      "recall\n",
      "[66.9,69.0]\n",
      "67.9\n",
      "sep\n",
      "[73.0,76.1]\n",
      "74.5\n",
      "\n",
      "\n",
      "Classification of smoker\n",
      "method_lr_basic:0.533, 0.535\n",
      "method_lr_basic:0.795, 0.781\n",
      "metric_only\n",
      "auc\n",
      "[52.5,54.4]\n",
      "53.5\n",
      "recall\n",
      "[75.9,77.8]\n",
      "76.8\n",
      "sep\n",
      "[28.7,32.0]\n",
      "30.3\n",
      "fusion\n",
      "auc\n",
      "[77.1,79.0]\n",
      "78.1\n",
      "recall\n",
      "[67.7,69.9]\n",
      "68.8\n",
      "sep\n",
      "[71.9,75.0]\n",
      "73.4\n",
      "\n",
      "\n",
      "Classification of drinker\n",
      "method_lr_basic:0.501, 0.499\n",
      "method_lr_basic:0.794, 0.78\n",
      "metric_only\n",
      "auc\n",
      "[49.1,50.6]\n",
      "49.9\n",
      "recall\n",
      "[10.6,12.0]\n",
      "11.3\n",
      "sep\n",
      "[88.4,90.5]\n",
      "89.4\n",
      "fusion\n",
      "auc\n",
      "[77.0,79.0]\n",
      "78.0\n",
      "recall\n",
      "[67.0,69.1]\n",
      "68.0\n",
      "sep\n",
      "[73.0,76.1]\n",
      "74.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indicator_name_list = ['Gender', 'Age', 'Diastolic Bp', 'Systolic Bp',  'Heart Rate', 'BMI', 'Course of Diabetes', 'Hypertension', 'Hyperlipidemia', 'Cardiovascular Disease', 'Classification of smoker', 'Classification of drinker']\n",
    "for idx in range(12):\n",
    "    idx  = idx + 1\n",
    "    curr_indicator_name = indicator_name_list[idx - 1]\n",
    "    print(curr_indicator_name)\n",
    "    input_dir = '/mnt/eye_team/kangdang/mmc_project_2023_submission/exp_records/fusion_exps/random_mi_single_variable'\n",
    "    metric_string = \"'\" + str(idx) + \"'\"\n",
    "    save_name = 'scenario_random_metric_and_fusion_score_' + curr_indicator_name + '.csv'\n",
    "    save_merged_dataframe(input_dir, metric_string, save_name, method_id_list = ['method_lr_basic'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bab3f71f-347e-4e1e-9d63-9d034f0ae9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc\n",
      "[75.7,78.6]\n",
      "77.2\n",
      "recall\n",
      "[72.0,74.7]\n",
      "73.4\n",
      "sep\n",
      "[65.9,70.8]\n",
      "68.4\n"
     ]
    }
   ],
   "source": [
    "test_result = pickle.load(open('/ssd/kangdang/mmc_project_2023_submission/external_test_code/img_only/top_checkpoint_ensemble_external_test_result.pickle', 'rb'))\n",
    "test_pred = test_result['pred_set']\n",
    "test_gt = test_result['gt_set']\n",
    "\n",
    "auc95, rec, sep, sep_90, global_auc, global_rec, global_sep, global_sep_90, global_largest_youden_th_fusion, global_given_recall_th_fusion = cal_ci95(test_gt, test_pred, 0.8)\n",
    "fpr, tpr, threshold = metrics.roc_curve(test_gt, test_pred)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('auc')\n",
    "print(\"[\" + \"{:.1f}\".format(auc95[0] * 100) + \",\" + \"{:.1f}\".format(auc95[1] * 100) + \"]\")\n",
    "print(\"{:.1f}\".format(auc * 100))\n",
    "print('recall')\n",
    "print(\"[\" + \"{:.1f}\".format(rec[0] * 100) + \",\" + \"{:.1f}\".format(rec[1] * 100) + \"]\")\n",
    "print(\"{:.1f}\".format(global_rec * 100))\n",
    "print('sep')\n",
    "print(\"[\" + \"{:.1f}\".format(sep[0] * 100) + \",\" + \"{:.1f}\".format(sep[1] * 100) + \"]\")\n",
    "print(\"{:.1f}\".format(global_sep * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756f37f-0618-44e5-a7ea-d599ada13ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
